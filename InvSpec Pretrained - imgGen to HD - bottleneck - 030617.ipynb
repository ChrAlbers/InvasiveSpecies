{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import data, io, filters, transform\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load functions to read images\n",
    "from keras.preprocessing import image as image_utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement of mission\n",
    "\n",
    "In the notebook \"Example pictures Simple Network\" we generated augmented image output beforehand of training. The purpose was to be able to have look at the image data after validation, in particular to be able to have a look at wrongly classified pictures. Here, we want to combine this with the pretrained VGG16 network, and also using bottleneck features. This refers to output of networks (not weights!) stored in a file on disk. Running the VGG16 network is very costly, so using bottleneck features could save some time that instead goes to training the dense layers we put on top of VGG16. However, we must make sure we have enough augmented pictures available.\n",
    "\n",
    "The code is mostly based on what can be found in this blog entry:\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define parameters:\n",
    "\n",
    "# Parameters for the transformations in Data Augmentation\n",
    "idg_width_shift_range = 0.2\n",
    "idg_height_shift_range = 0.2\n",
    "idg_shear_range = 0.2\n",
    "idg_zoom_range = 0.2\n",
    "idg_horflip = True\n",
    "\n",
    "# Parameters for data output (image size, number of trafos)\n",
    "target_size = (224, 224)\n",
    "num_versions = 3 # How many versions of each picture to generate\n",
    "input_shape = target_size + (3, )\n",
    "test_num_images = 40 # Do set to large value to process all images\n",
    "\n",
    "# Fraction of data for validation\n",
    "val_fraction = 0.5\n",
    "\n",
    "# Parameters for training\n",
    "batch_size = 20\n",
    "\n",
    "# threshold for classification\n",
    "threshold_class = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read labels of the training data\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make to image augmentation data generators. One without transformation (for validation data)\n",
    "no_transform_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "image_prep_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   width_shift_range = idg_width_shift_range,\n",
    "                                   height_shift_range = idg_height_shift_range,\n",
    "                                   shear_range = idg_shear_range,\n",
    "                                   zoom_range = idg_zoom_range,\n",
    "                                   horizontal_flip = idg_horflip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate folder structure\n",
    "\n",
    "The first preprocessing step is to generate the pictures. We will save them in folders data/train_vgg and data/val_vgg to keep them separate from the other network runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I am getting weird error messages sometimes when running this cell. Don't know why.\n",
    "# I suspect it is probably a bad idea running file io in loops; seems to do things\n",
    "# out of the order as specified here, what's with \n",
    "\n",
    "data_root_dir = \"data/vgg_impregen_bottleneck_vgg/\"\n",
    "\n",
    "subdirlist = [\"train/0/\", \"train/1/\",\n",
    "              \"val/0/\", \"val/1/\",\n",
    "              \"test_0\", \"test_1\"]\n",
    "\n",
    "\n",
    "dirlist = []\n",
    "for subdir in subdirlist:\n",
    "    dirlist.append(data_root_dir + subdir)\n",
    "\n",
    "\n",
    "# The test folders are not really test data. Instead, they keep a mirror of the validation\n",
    "# data. The pictures will then be classified once again by our network and depending on\n",
    "# correctness of result put in a subfolder. This somewhat convoluted scheme is necessary\n",
    "# because of the syntax and limitation of keras.\n",
    "\n",
    "for element in dirlist:\n",
    "    if os.path.exists(element):\n",
    "        shutil.rmtree(element)\n",
    "\n",
    "for element in dirlist:\n",
    "    os.makedirs(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for file_counter in range(0, min(test_num_images, train_labels.shape[0])):\n",
    "    file_id = str(train_labels[\"name\"][file_counter])\n",
    "    \n",
    "    # Load image, make it an array so the flow()-method can work with it.\n",
    "    img = image_utils.load_img(\"data/train/\" + file_id + \".jpg\", target_size = target_size)\n",
    "    img = image_utils.img_to_array(img)\n",
    "    img = img.reshape((1, ) + img.shape)\n",
    "    \n",
    "    # Make sure the file names start with the number of the source file and the label\n",
    "    file_prefix = file_id.rjust(4, \"0\") + \"_\" + str(train_labels[\"invasive\"][file_counter]) + \"_\"\n",
    "    \n",
    "    if np.random.rand() < val_fraction:\n",
    "        save_to_dir = data_root_dir + \"val/\" + str(train_labels[\"invasive\"][file_counter]) + \"/\"\n",
    "        for batch in no_transform_datagen.flow(x = img, batch_size = 1, save_to_dir = save_to_dir,\n",
    "                                            save_prefix = file_prefix, save_format = \"jpg\"):\n",
    "            break # Stop the image generation after the first image\n",
    "    else:\n",
    "        save_to_dir = data_root_dir + \"train/\" + str(train_labels[\"invasive\"][file_counter]) + \"/\"\n",
    "        counter = 0\n",
    "        for batch in image_prep_gen.flow(x = img, batch_size = 1, save_to_dir = save_to_dir,\n",
    "                                            save_prefix = file_prefix, save_format = \"jpg\"):\n",
    "            counter += 1\n",
    "            if counter > (num_versions - 1):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_train_0 = len(os.listdir(data_root_dir + \"train/0\"))\n",
    "num_images_train_1 = len(os.listdir(data_root_dir + \"train/1\"))\n",
    "num_images_val_0 = len(os.listdir(data_root_dir + \"val/0\"))\n",
    "num_images_val_1 = len(os.listdir(data_root_dir + \"val/1\"))\n",
    "\n",
    "num_images_train_0\n",
    "#num_images_train_1\n",
    "\n",
    "\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 images belonging to 2 classes.\n",
      "Duration of training 48 images was 810.42\n"
     ]
    }
   ],
   "source": [
    "# Get the number of images in each subfolder\n",
    "num_images_train_0 = len(os.listdir(data_root_dir + \"train/0\"))\n",
    "num_images_train_1 = len(os.listdir(data_root_dir + \"train/1\"))\n",
    "num_images_val_0 = len(os.listdir(data_root_dir + \"val/0\"))\n",
    "num_images_val_1 = len(os.listdir(data_root_dir + \"val/1\"))\n",
    "\n",
    "images_to_train = num_images_train_0 + num_images_train_1\n",
    "\n",
    "imagenet_model = applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "\n",
    "generator_for_bottleneck = no_transform_datagen.flow_from_directory(data_root_dir + \"train\",\n",
    "                                                                   target_size = target_size,\n",
    "                                                                   batch_size = batch_size,\n",
    "                                                                   class_mode = None,\n",
    "                                                                   shuffle = False)\n",
    "startzeit = time.time()\n",
    "bottleneck_train = imagenet_model.predict_generator(generator_for_bottleneck, images_to_train)\n",
    "endzeit = time.time()\n",
    "\n",
    "print(\"Duration of training \" + str(images_to_train) + \" images was \" + str(round(endzeit - startzeit, 2)))\n",
    "\n",
    "# The write command in the blog does not work. Somehow, the write mode must\n",
    "# be set to \"wb\" instead of only \"w\"\n",
    "np.save(open('bottleneck_030617.npy', 'wb'), bottleneck_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/val',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size = 1,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and convolutional network on top of image net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagenet_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=imagenet_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=imagenet_model.input, outputs=top_model(imagenet_model.output))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fix pretrained layers from imagenet\n",
    "for layer in model.layers[:17]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model which was trained before\n",
    "model.load_weights('top_model_2017.05.24.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('top_model_2017.05.25.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict_generator(test_generator, test_generator.n, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = list()\n",
    "for name_str in test_generator.filenames:\n",
    "    name_str=name_str[5:-4]\n",
    "    name.append(int(name_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_results = pd.DataFrame(name, columns=[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_results[\"invasive\"] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_results.sort(\"name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_results.to_csv(\"data\\\\Submission_5_CNN_Pretrained-2017.05.25.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
